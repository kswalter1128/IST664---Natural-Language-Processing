{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "## CODE IDEAS FOR HMW 2, Exploratory exercise for sentiment analysis\r\n",
    "# finding adverb and adjective phrases, and computing basic statistics\r\n",
    "\r\n",
    "# importing required nltk libraries\r\n",
    "import nltk\r\n",
    "from nltk import sent_tokenize\r\n",
    "\r\n",
    "# importing the guttenburg package\r\n",
    "from gutenberg.acquire import load_etext\r\n",
    "from gutenberg.cleanup import strip_headers\r\n",
    "\r\n",
    "#importing the text\r\n",
    "annaK = strip_headers(load_etext(1399)).strip() # book1\r\n",
    "gatsby = strip_headers(load_etext(64317)).strip() #book 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#inspecting annaK\r\n",
    "\r\n",
    "print(annaK[1:150])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Illustration]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ANNA KARENINA \n",
      "\n",
      " by Leo Tolstoy \n",
      "\n",
      " Translated by Constance Garnett \n",
      "\n",
      "Contents\n",
      "\n",
      "\n",
      " PART ONE\n",
      " PART TWO\n",
      " PART THREE\n",
      " \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#inspecting Gatsby\r\n",
    "print(gatsby[1:150])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "he Great Gatsby\n",
      "\t\t\t\t  by\n",
      "\t\t\t F. Scott Fitzgerald\n",
      "\n",
      "\n",
      "                           Table of Contents\n",
      "\n",
      "I\n",
      "II\n",
      "III\n",
      "IV\n",
      "V\n",
      "VI\n",
      "VII\n",
      "VIII\n",
      "IX\n",
      "\n",
      "\n",
      "   \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Preprocessing, as explained in the Labs\r\n",
    "# Separate the text into sentences first\r\n",
    "annaKSplit = nltk.sent_tokenize(annaK)\r\n",
    "print(annaKSplit[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['[Illustration]\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n ANNA KARENINA \\r\\n\\r\\n by Leo Tolstoy \\r\\n\\r\\n Translated by Constance Garnett \\r\\n\\r\\nContents\\r\\n\\r\\n\\r\\n PART ONE\\r\\n PART TWO\\r\\n PART THREE\\r\\n PART FOUR\\r\\n PART FIVE\\r\\n PART SIX\\r\\n PART SEVEN\\r\\n PART EIGHT\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nPART ONE\\r\\n\\r\\nChapter 1\\r\\n\\r\\n\\r\\nHappy families are all alike; every unhappy family is unhappy in its\\r\\nown way.', 'Everything was in confusion in the Oblonskys’ house.', 'The wife had\\r\\ndiscovered that the husband was carrying on an intrigue with a French\\r\\ngirl, who had been a governess in their family, and she had announced\\r\\nto her husband that she could not go on living in the same house with\\r\\nhim.', 'This position of affairs had now lasted three days, and not only\\r\\nthe husband and wife themselves, but all the members of their family\\r\\nand household, were painfully conscious of it.', 'Every person in the\\r\\nhouse felt that there was no sense in their living together, and that\\r\\nthe stray people brought together by chance in any inn had more in\\r\\ncommon with one another than they, the members of the family and\\r\\nhousehold of the Oblonskys.', 'The wife did not leave her own room, the\\r\\nhusband had not been at home for three days.', 'The children ran wild all\\r\\nover the house; the English governess quarreled with the housekeeper,\\r\\nand wrote to a friend asking her to look out for a new situation for\\r\\nher; the man-cook had walked off the day before just at dinner time;\\r\\nthe kitchen-maid, and the coachman had given warning.', 'Three days after the quarrel, Prince Stepan Arkadyevitch\\r\\nOblonsky—Stiva, as he was called in the fashionable world—woke up at\\r\\nhis usual hour, that is, at eight o’clock in the morning, not in his\\r\\nwife’s bedroom, but on the leather-covered sofa in his study.', 'He turned\\r\\nover his stout, well-cared-for person on the springy sofa, as though he\\r\\nwould sink into a long sleep again; he vigorously embraced the pillow\\r\\non the other side and buried his face in it; but all at once he jumped\\r\\nup, sat up on the sofa, and opened his eyes.', '“Yes, yes, how was it now?” he thought, going over his dream.']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Sentenct Tokenizing of Gatsby\r\n",
    "gatsbySplit = nltk.sent_tokenize(gatsby)\r\n",
    "print(gatsbySplit[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['The Great Gatsby\\r\\n\\t\\t\\t\\t  by\\r\\n\\t\\t\\t F. Scott Fitzgerald\\r\\n\\r\\n\\r\\n                           Table of Contents\\r\\n\\r\\nI\\r\\nII\\r\\nIII\\r\\nIV\\r\\nV\\r\\nVI\\r\\nVII\\r\\nVIII\\r\\nIX\\r\\n\\r\\n\\r\\n                              Once again\\r\\n                                  to\\r\\n                                 Zelda\\r\\n\\r\\n  Then wear the gold hat, if that will move her;\\r\\n  If you can bounce high, bounce for her too,\\r\\n  Till she cry “Lover, gold-hatted, high-bouncing lover,\\r\\n  I must have you!”\\r\\n\\r\\n  Thomas Parke d’Invilliers\\r\\n\\r\\n\\r\\n                                  I\\r\\n\\r\\nIn my younger and more vulnerable years my father gave me some advice\\r\\nthat I’ve been turning over in my mind ever since.', '“Whenever you feel like criticizing anyone,” he told me, “just\\r\\nremember that all the people in this world haven’t had the advantages\\r\\nthat you’ve had.”\\r\\n\\r\\nHe didn’t say any more, but we’ve always been unusually communicative\\r\\nin a reserved way, and I understood that he meant a great deal more\\r\\nthan that.', 'In consequence, I’m inclined to reserve all judgements, a\\r\\nhabit that has opened up many curious natures to me and also made me\\r\\nthe victim of not a few veteran bores.', 'The abnormal mind is quick to\\r\\ndetect and attach itself to this quality when it appears in a normal\\r\\nperson, and so it came about that in college I was unjustly accused of\\r\\nbeing a politician, because I was privy to the secret griefs of wild,\\r\\nunknown men.', 'Most of the confidences were unsought—frequently I have\\r\\nfeigned sleep, preoccupation, or a hostile levity when I realized by\\r\\nsome unmistakable sign that an intimate revelation was quivering on\\r\\nthe horizon; for the intimate revelations of young men, or at least\\r\\nthe terms in which they express them, are usually plagiaristic and\\r\\nmarred by obvious suppressions.', 'Reserving judgements is a matter of\\r\\ninfinite hope.', 'I am still a little afraid of missing something if I\\r\\nforget that, as my father snobbishly suggested, and I snobbishly\\r\\nrepeat, a sense of the fundamental decencies is parcelled out\\r\\nunequally at birth.', 'And, after boasting this way of my tolerance, I come to the admission\\r\\nthat it has a limit.', 'Conduct may be founded on the hard rock or the\\r\\nwet marshes, but after a certain point I don’t care what it’s founded\\r\\non.', 'When I came back from the East last autumn I felt that I wanted\\r\\nthe world to be in uniform and at a sort of moral attention forever; I\\r\\nwanted no more riotous excursions with privileged glimpses into the\\r\\nhuman heart.']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Apply the word tokenizer to each sentence\r\n",
    "annaKToken = [nltk.word_tokenize(sent) for sent in annaKSplit]\r\n",
    "print(annaKToken[:2])\r\n",
    "#the output is a list of strings that contains the sentences\r\n",
    "type(annaKToken)\r\n",
    "len(annaKToken)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['[', 'Illustration', ']', 'ANNA', 'KARENINA', 'by', 'Leo', 'Tolstoy', 'Translated', 'by', 'Constance', 'Garnett', 'Contents', 'PART', 'ONE', 'PART', 'TWO', 'PART', 'THREE', 'PART', 'FOUR', 'PART', 'FIVE', 'PART', 'SIX', 'PART', 'SEVEN', 'PART', 'EIGHT', 'PART', 'ONE', 'Chapter', '1', 'Happy', 'families', 'are', 'all', 'alike', ';', 'every', 'unhappy', 'family', 'is', 'unhappy', 'in', 'its', 'own', 'way', '.'], ['Everything', 'was', 'in', 'confusion', 'in', 'the', 'Oblonskys', '’', 'house', '.']]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16787"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "gatsbyToken = [nltk.word_tokenize(sent) for sent in gatsbySplit]\r\n",
    "print(gatsbyToken[:2])\r\n",
    "\r\n",
    "type(gatsbyToken)\r\n",
    "len(gatsbyToken)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['The', 'Great', 'Gatsby', 'by', 'F.', 'Scott', 'Fitzgerald', 'Table', 'of', 'Contents', 'I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'Once', 'again', 'to', 'Zelda', 'Then', 'wear', 'the', 'gold', 'hat', ',', 'if', 'that', 'will', 'move', 'her', ';', 'If', 'you', 'can', 'bounce', 'high', ',', 'bounce', 'for', 'her', 'too', ',', 'Till', 'she', 'cry', '“', 'Lover', ',', 'gold-hatted', ',', 'high-bouncing', 'lover', ',', 'I', 'must', 'have', 'you', '!', '”', 'Thomas', 'Parke', 'd', '’', 'Invilliers', 'I', 'In', 'my', 'younger', 'and', 'more', 'vulnerable', 'years', 'my', 'father', 'gave', 'me', 'some', 'advice', 'that', 'I', '’', 've', 'been', 'turning', 'over', 'in', 'my', 'mind', 'ever', 'since', '.'], ['“', 'Whenever', 'you', 'feel', 'like', 'criticizing', 'anyone', ',', '”', 'he', 'told', 'me', ',', '“', 'just', 'remember', 'that', 'all', 'the', 'people', 'in', 'this', 'world', 'haven', '’', 't', 'had', 'the', 'advantages', 'that', 'you', '’', 've', 'had.', '”', 'He', 'didn', '’', 't', 'say', 'any', 'more', ',', 'but', 'we', '’', 've', 'always', 'been', 'unusually', 'communicative', 'in', 'a', 'reserved', 'way', ',', 'and', 'I', 'understood', 'that', 'he', 'meant', 'a', 'great', 'deal', 'more', 'than', 'that', '.']]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2439"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "## POS Tagging, to retrieve adjective (JJs) and adverb (RBs) tags\r\n",
    "# use the stanford POS Tagger to POS tag takens of each sentence (nltk's default tagger)\r\n",
    "\r\n",
    "annaTagged = [nltk.pos_tag(tokens) for tokens in annaKToken]\r\n",
    "print(annaTagged[:2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[('[', 'JJ'), ('Illustration', 'NNP'), (']', 'NNP'), ('ANNA', 'NNP'), ('KARENINA', 'NNP'), ('by', 'IN'), ('Leo', 'NNP'), ('Tolstoy', 'NNP'), ('Translated', 'VBN'), ('by', 'IN'), ('Constance', 'NNP'), ('Garnett', 'NNP'), ('Contents', 'NNP'), ('PART', 'NNP'), ('ONE', 'NNP'), ('PART', 'NNP'), ('TWO', 'NNP'), ('PART', 'NNP'), ('THREE', 'NNP'), ('PART', 'NNP'), ('FOUR', 'NNP'), ('PART', 'NNP'), ('FIVE', 'NNP'), ('PART', 'NNP'), ('SIX', 'NNP'), ('PART', 'NNP'), ('SEVEN', 'NNP'), ('PART', 'NNP'), ('EIGHT', 'NNP'), ('PART', 'NNP'), ('ONE', 'NNP'), ('Chapter', 'NN'), ('1', 'CD'), ('Happy', 'JJ'), ('families', 'NNS'), ('are', 'VBP'), ('all', 'DT'), ('alike', 'RB'), (';', ':'), ('every', 'DT'), ('unhappy', 'JJ'), ('family', 'NN'), ('is', 'VBZ'), ('unhappy', 'JJ'), ('in', 'IN'), ('its', 'PRP$'), ('own', 'JJ'), ('way', 'NN'), ('.', '.')], [('Everything', 'NN'), ('was', 'VBD'), ('in', 'IN'), ('confusion', 'NN'), ('in', 'IN'), ('the', 'DT'), ('Oblonskys', 'NNP'), ('’', 'NNP'), ('house', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "gatsbyTagged = [nltk.pos_tag(T) for T in gatsbyToken]\r\n",
    "print(gatsbyTagged[:2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[('The', 'DT'), ('Great', 'NNP'), ('Gatsby', 'NNP'), ('by', 'IN'), ('F.', 'NNP'), ('Scott', 'NNP'), ('Fitzgerald', 'NNP'), ('Table', 'NNP'), ('of', 'IN'), ('Contents', 'NNP'), ('I', 'PRP'), ('II', 'NNP'), ('III', 'NNP'), ('IV', 'NNP'), ('V', 'NNP'), ('VI', 'NNP'), ('VII', 'NNP'), ('VIII', 'NNP'), ('IX', 'NNP'), ('Once', 'RB'), ('again', 'RB'), ('to', 'TO'), ('Zelda', 'NNP'), ('Then', 'RB'), ('wear', 'VBD'), ('the', 'DT'), ('gold', 'NN'), ('hat', 'NN'), (',', ','), ('if', 'IN'), ('that', 'DT'), ('will', 'MD'), ('move', 'VB'), ('her', 'PRP$'), (';', ':'), ('If', 'IN'), ('you', 'PRP'), ('can', 'MD'), ('bounce', 'VB'), ('high', 'JJ'), (',', ','), ('bounce', 'NN'), ('for', 'IN'), ('her', 'PRP$'), ('too', 'RB'), (',', ','), ('Till', 'NNP'), ('she', 'PRP'), ('cry', 'VBD'), ('“', 'NNP'), ('Lover', 'NNP'), (',', ','), ('gold-hatted', 'JJ'), (',', ','), ('high-bouncing', 'JJ'), ('lover', 'NN'), (',', ','), ('I', 'PRP'), ('must', 'MD'), ('have', 'VB'), ('you', 'PRP'), ('!', '.'), ('”', 'VB'), ('Thomas', 'NNP'), ('Parke', 'NNP'), ('d', 'NN'), ('’', 'NN'), ('Invilliers', 'NNP'), ('I', 'PRP'), ('In', 'IN'), ('my', 'PRP$'), ('younger', 'JJR'), ('and', 'CC'), ('more', 'RBR'), ('vulnerable', 'JJ'), ('years', 'NNS'), ('my', 'PRP$'), ('father', 'NN'), ('gave', 'VBD'), ('me', 'PRP'), ('some', 'DT'), ('advice', 'NN'), ('that', 'IN'), ('I', 'PRP'), ('’', 'VBP'), ('ve', 'RB'), ('been', 'VBN'), ('turning', 'VBG'), ('over', 'IN'), ('in', 'IN'), ('my', 'PRP$'), ('mind', 'NN'), ('ever', 'RB'), ('since', 'IN'), ('.', '.')], [('“', 'VB'), ('Whenever', 'WRB'), ('you', 'PRP'), ('feel', 'VBP'), ('like', 'IN'), ('criticizing', 'VBG'), ('anyone', 'NN'), (',', ','), ('”', 'NN'), ('he', 'PRP'), ('told', 'VBD'), ('me', 'PRP'), (',', ','), ('“', 'VB'), ('just', 'RB'), ('remember', 'VB'), ('that', 'IN'), ('all', 'PDT'), ('the', 'DT'), ('people', 'NNS'), ('in', 'IN'), ('this', 'DT'), ('world', 'NN'), ('haven', 'NN'), ('’', 'NNP'), ('t', 'NN'), ('had', 'VBD'), ('the', 'DT'), ('advantages', 'NNS'), ('that', 'IN'), ('you', 'PRP'), ('’', 'VBP'), ('ve', 'JJ'), ('had.', 'NN'), ('”', 'NN'), ('He', 'PRP'), ('didn', 'VBZ'), ('’', 'JJ'), ('t', 'NNS'), ('say', 'VBP'), ('any', 'DT'), ('more', 'JJR'), (',', ','), ('but', 'CC'), ('we', 'PRP'), ('’', 'VBP'), ('ve', 'JJ'), ('always', 'RB'), ('been', 'VBN'), ('unusually', 'RB'), ('communicative', 'JJ'), ('in', 'IN'), ('a', 'DT'), ('reserved', 'JJ'), ('way', 'NN'), (',', ','), ('and', 'CC'), ('I', 'PRP'), ('understood', 'VBP'), ('that', 'IN'), ('he', 'PRP'), ('meant', 'VBD'), ('a', 'DT'), ('great', 'JJ'), ('deal', 'NN'), ('more', 'JJR'), ('than', 'IN'), ('that', 'DT'), ('.', '.')]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Following our NLTK textbook, chapter on Information Extraction--Chunking (https://www.nltk.org/book/ch07.html)\r\n",
    "\r\n",
    "# Using CHUNKING to parse sentences \r\n",
    "# to look for \"adjective phrases\", i.e. phrases (or chunks) that have adverbs and adjectives ('RB'+'JJ')\r\n",
    "# First step: writing a grammar that defines the POS in the chunk\r\n",
    "# we name this grammar \"ADJPH\" (\"ADJective PHrase\") using regexes \r\n",
    "\r\n",
    "import re\r\n",
    "grammar_adjph = \"ADJPH: {<RB.?>+<JJ.?>}\"\r\n",
    "# This regex reads as: \"find groups (\"< >\") of RBs (adverbs) together with groups of JJs (adjectives), with groups defineds as\r\n",
    "# RBs with any ending (the \".\" is a placeholder or wildcard for the \"R\" and the \"S\" at the end of RBR and RBS, \r\n",
    "# while \"?\" indicates \"optional character\" so RB can be found alone as well). Same regex operators apply to JJs.\r\n",
    "\r\n",
    "# Second step: import the nltk parser to process each sentence\r\n",
    "chunk_parser_adj = nltk.RegexpParser(grammar_adjph)\r\n",
    "\r\n",
    "anna_adjph_tags = []\r\n",
    "for sent in annaTagged:\r\n",
    "    if len(sent) > 0:\r\n",
    "        tree = chunk_parser_adj.parse(sent)\r\n",
    "        for subtree in tree.subtrees():\r\n",
    "            if subtree.label() == 'ADJPH':\r\n",
    "                anna_adjph_tags.append(subtree)\r\n",
    "                \r\n",
    "# Visualizing the actual adjective phrase\r\n",
    "anna_adjective_phrases = []\r\n",
    "for sent in anna_adjph_tags:\r\n",
    "    temp = ''\r\n",
    "    for w, t in sent:\r\n",
    "        temp += w+ ' '    \r\n",
    "    anna_adjective_phrases.append(temp)\r\n",
    "    \r\n",
    "print('First 10 adjective phrases: ', anna_adjective_phrases[:10])\r\n",
    "\r\n",
    "\r\n",
    "# Following our NLTK textbook, chapter 1 on Language Processing (https://www.nltk.org/book/ch01.html)\r\n",
    "\r\n",
    "## FREQUENCY DISTRIBUTIONS\r\n",
    "# Top 50 adjective phrases\r\n",
    "anna_freq_adjph = nltk.FreqDist(anna_adjective_phrases)\r\n",
    "\r\n",
    "print('Top adjective phrases by frequency: ')\r\n",
    "for word, freq in anna_freq_adjph.most_common(50):\r\n",
    "    print(word, freq)\r\n",
    "\r\n",
    "            \r\n",
    "#print the list of our sentences:\r\n",
    "print('Length of adjective phrase sentences: ', len(anna_adjph_tags))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First 10 adjective phrases:  ['painfully conscious ', 'very nice ', 'most awful ', 'acutely painful ', 'not so much ', 'very disgraceful ', 'therefore idiotic ', 'no longer young ', 'most complex ', 'sly smile ']\n",
      "Top adjective phrases by frequency: \n",
      "so much  67\n",
      "very glad  45\n",
      "so many  25\n",
      "too much  23\n",
      "very nice  20\n",
      "once more  18\n",
      "very good  17\n",
      "most important  14\n",
      "so glad  14\n",
      "so little  13\n",
      "very much  12\n",
      "not so much  11\n",
      "so good  11\n",
      "as much  11\n",
      "very interesting  11\n",
      "so happy  10\n",
      "very sorry  10\n",
      "so awful  10\n",
      "very instant  9\n",
      "too late  8\n",
      "utterly impossible  8\n",
      "very grateful  8\n",
      "quite different  7\n",
      "utterly unable  7\n",
      "very busy  6\n",
      "very best  6\n",
      "Very good  6\n",
      "not true  6\n",
      "not good  6\n",
      "not nice  6\n",
      "not angry  6\n",
      "not afraid  6\n",
      "so simple  6\n",
      "still more  6\n",
      "even more  6\n",
      "very attractive  6\n",
      "“ Good  5\n",
      "scarcely perceptible  5\n",
      "so strange  5\n",
      "s impossible  5\n",
      "however much  5\n",
      "very simple  5\n",
      "Very glad  5\n",
      "very young  5\n",
      "so difficult  5\n",
      "very happy  5\n",
      "very same  5\n",
      "not last  5\n",
      "most difficult  5\n",
      "most intimate  5\n",
      "Length of adjective phrase sentences:  2687\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "gatsby_adjph_tags = []\r\n",
    "for sent in gatsbyTagged:\r\n",
    "    if len(sent) > 0:\r\n",
    "        tree = chunk_parser_adj.parse(sent)\r\n",
    "        for subtree in tree.subtrees():\r\n",
    "            if subtree.label() == 'ADJPH':\r\n",
    "                gatsby_adjph_tags.append(subtree)\r\n",
    "                \r\n",
    "# Visualizing the actual adjective phrase\r\n",
    "gatsby_adjective_phrases = []\r\n",
    "for sent in gatsby_adjph_tags:\r\n",
    "    temp = ''\r\n",
    "    for w, t in sent:\r\n",
    "        temp += w+ ' '    \r\n",
    "    gatsby_adjective_phrases.append(temp)\r\n",
    "    \r\n",
    "print('First 10 adjective phrases: ', gatsby_adjective_phrases[:10])\r\n",
    "\r\n",
    "\r\n",
    "# Following our NLTK textbook, chapter 1 on Language Processing (https://www.nltk.org/book/ch01.html)\r\n",
    "\r\n",
    "## FREQUENCY DISTRIBUTIONS\r\n",
    "# Top 50 adjective phrases\r\n",
    "gatsby_freq_adjph = nltk.FreqDist(gatsby_adjective_phrases)\r\n",
    "\r\n",
    "print('Top adjective phrases by frequency: ')\r\n",
    "for word, freq in gatsby_freq_adjph.most_common(50):\r\n",
    "    print(word, freq)\r\n",
    "\r\n",
    "            \r\n",
    "#print the list of our sentences:\r\n",
    "print('Length of adjective phrase sentences: ', len(gatsby_adjph_tags))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First 10 adjective phrases:  ['more vulnerable ', 'unusually communicative ', 'usually plagiaristic ', 'more riotous ', 'not likely ', 'rather hard-boiled ', 'very grave ', 'so much ', 'so much ', 'rather literary ']\n",
      "Top adjective phrases by frequency: \n",
      "so much  4\n",
      "“ Good  4\n",
      "very good  3\n",
      "too much  3\n",
      "more interesting  2\n",
      "” insisted  2\n",
      "m glad  2\n",
      "once more  2\n",
      "too hot  2\n",
      "very much  2\n",
      "s much  2\n",
      "so hot  2\n",
      "too late  2\n",
      "more vulnerable  1\n",
      "unusually communicative  1\n",
      "usually plagiaristic  1\n",
      "more riotous  1\n",
      "not likely  1\n",
      "rather hard-boiled  1\n",
      "very grave  1\n",
      "rather literary  1\n",
      "very solemn  1\n",
      "most domesticated  1\n",
      "not perfect  1\n",
      "less fashionable  1\n",
      "most superficial  1\n",
      "only fifty  1\n",
      "most powerful  1\n",
      "there unrestfully wherever  1\n",
      "even more  1\n",
      "rather hard  1\n",
      "m stronger  1\n",
      "never intimate  1\n",
      "completely stationary  1\n",
      "quite likely  1\n",
      "very witty  1\n",
      "back again—the  1\n",
      "anywhere else.  1\n",
      "as much  1\n",
      "as long  1\n",
      "as cool  1\n",
      "sharply different  1\n",
      "continually disappointed  1\n",
      "rather impressive  1\n",
      "over tonight.  1\n",
      "forward unashamed  1\n",
      "very romantic  1\n",
      "perfectly tangible  1\n",
      "pleasantly interested  1\n",
      "very bad  1\n",
      "Length of adjective phrase sentences:  295\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Now we look for \"adverb phrases\" or chunks that have 2 consecutive adverbs ('RB')\r\n",
    "# First step: writing a grammar that defines POS rules of the adverb phrase the chunk\r\n",
    "# we name this grammar \"ADVPH\" (\"ADVerb PHrase\")\r\n",
    "grammar_advph = \"ADVPH: {<RB>+<RB>}\"\r\n",
    "\r\n",
    "# Second step: import the nltk parser to process each sentence\r\n",
    "chunk_parser_adv = nltk.RegexpParser(grammar_advph)\r\n",
    "\r\n",
    "anna_advph_tags = []\r\n",
    "for sent in annaTagged:\r\n",
    "    if len(sent) > 0:\r\n",
    "        tree = chunk_parser_adv.parse(sent)\r\n",
    "        for subtree in tree.subtrees():\r\n",
    "            if subtree.label() == 'ADVPH':\r\n",
    "                anna_advph_tags.append(subtree)\r\n",
    "                \r\n",
    "# Visualizing the actual adjective phrase\r\n",
    "adverb_phrases = []\r\n",
    "for sent in anna_advph_tags:\r\n",
    "    temp = ''\r\n",
    "    for w, t in sent:\r\n",
    "        temp += w+ ' '    \r\n",
    "    adverb_phrases.append(temp)\r\n",
    "    \r\n",
    "print('First 10 adverb phrases: ', adverb_phrases[:10])\r\n",
    "\r\n",
    "# top 50 adjective phrases\r\n",
    "anna_freq_advph = nltk.FreqDist(adverb_phrases)\r\n",
    "\r\n",
    "print('Top adverb phrases by frequency: ')\r\n",
    "for word, freq in anna_freq_advph.most_common(50):\r\n",
    "    print(word, freq)\r\n",
    "\r\n",
    "            \r\n",
    "#print the list of our sentences:\r\n",
    "print('Length of adverb phrase sentences: ', len(anna_advph_tags))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First 10 adverb phrases:  ['not only ', '“ Now ', 'm not ', 'perfectly still ', 'so often ', 'not so ', '—utterly involuntarily ', 'never clearly ', 'long ago ', 'till now ']\n",
      "Top adverb phrases by frequency: \n",
      "“ Well  94\n",
      "m not  56\n",
      "as soon  47\n",
      "not merely  42\n",
      "not even  42\n",
      "only just  39\n",
      "very well  38\n",
      "not yet  36\n",
      "not only  32\n",
      "so well  32\n",
      "so long  26\n",
      "not so  24\n",
      "so much  22\n",
      "back again  21\n",
      "as far  21\n",
      "just now  21\n",
      "long ago  20\n",
      "very much  19\n",
      "not simply  17\n",
      "so far  17\n",
      "as well  15\n",
      "so often  14\n",
      "not quite  14\n",
      "not now  14\n",
      "quite well  14\n",
      "As soon  12\n",
      "s just  12\n",
      "“ Now  11\n",
      "here long  10\n",
      "not long  10\n",
      "not far  10\n",
      "quite differently  9\n",
      "not once  9\n",
      "just as  8\n",
      "down again  8\n",
      "down beside  8\n",
      "even now  8\n",
      "almost always  7\n",
      "ever so  7\n",
      "obviously not  7\n",
      "up too  7\n",
      "so too  7\n",
      "now so  7\n",
      "not alone  6\n",
      "only then  6\n",
      "so quickly  6\n",
      "perfectly well  6\n",
      "always so  6\n",
      "Just now  6\n",
      "very quickly  6\n",
      "Length of adverb phrase sentences:  2054\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Now we look for \"adverb phrases\" or chunks that have 2 consecutive adverbs ('RB')\r\n",
    "# First step: writing a grammar that defines POS rules of the adverb phrase the chunk\r\n",
    "# we name this grammar \"ADVPH\" (\"ADVerb PHrase\")\r\n",
    "grammar_advph = \"ADVPH: {<RB>+<RB>}\"\r\n",
    "\r\n",
    "# Second step: import the nltk parser to process each sentence\r\n",
    "chunk_parser_adv = nltk.RegexpParser(grammar_advph)\r\n",
    "\r\n",
    "gatsby_advph_tags = []\r\n",
    "for sent in gatsbyTagged:\r\n",
    "    if len(sent) > 0:\r\n",
    "        tree = chunk_parser_adv.parse(sent)\r\n",
    "        for subtree in tree.subtrees():\r\n",
    "            if subtree.label() == 'ADVPH':\r\n",
    "                gatsby_advph_tags.append(subtree)\r\n",
    "                \r\n",
    "# Visualizing the actual adjective phrase\r\n",
    "gatsby_adverb_phrases = []\r\n",
    "for sent in gatsby_advph_tags:\r\n",
    "    temp = ''\r\n",
    "    for w, t in sent:\r\n",
    "        temp += w+ ' '    \r\n",
    "    gatsby_adverb_phrases.append(temp)\r\n",
    "    \r\n",
    "print('First 10 adverb phrases: ', gatsby_adverb_phrases[:10])\r\n",
    "\r\n",
    "# top 50 adjective phrases\r\n",
    "gatsby_freq_advph = nltk.FreqDist(gatsby_adverb_phrases)\r\n",
    "\r\n",
    "print('Top adverb phrases by frequency: ')\r\n",
    "for word, freq in gatsby_freq_advph.most_common(50):\r\n",
    "    print(word, freq)\r\n",
    "\r\n",
    "            \r\n",
    "#print the list of our sentences:\r\n",
    "print('Length of adverb phrase sentences: ', len(gatsby_advph_tags))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First 10 adverb phrases:  ['Once again ', 'all right ', 'so thoroughly ', 'lonely no ', 'over there ', 'there unrestfully ', 'aggressively forward ', 'Not even ', '“ Now ', 'about restlessly ']\n",
      "Top adverb phrases by frequency: \n",
      "“ Well  5\n",
      "so long  5\n",
      "“ Now  4\n",
      "far away  4\n",
      "d never  4\n",
      "so much  3\n",
      "m not  3\n",
      "no longer  3\n",
      "ve never  3\n",
      "right now  3\n",
      "all right  2\n",
      "then back  2\n",
      "somewhere before  2\n",
      "never quite  2\n",
      "not enough  2\n",
      "“ Even  2\n",
      "as long  2\n",
      "s so  2\n",
      "back again  2\n",
      "never even  2\n",
      "so far  2\n",
      "so often  2\n",
      "very slowly  2\n",
      "s too  2\n",
      "even then  2\n",
      "pretty soon  2\n",
      "Once again  1\n",
      "so thoroughly  1\n",
      "lonely no  1\n",
      "over there  1\n",
      "there unrestfully  1\n",
      "aggressively forward  1\n",
      "Not even  1\n",
      "about restlessly  1\n",
      "around again  1\n",
      "slightly forward  1\n",
      "almost imperceptibly  1\n",
      "then quickly  1\n",
      "very profound  1\n",
      "almost immediately  1\n",
      "forward breathlessly  1\n",
      "forward again  1\n",
      "not even faintly  1\n",
      "Then suddenly  1\n",
      "then miserably  1\n",
      "very well  1\n",
      "rather feebly  1\n",
      "long ago  1\n",
      "over often  1\n",
      "together there  1\n",
      "Length of adverb phrase sentences:  222\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Top 50 adjective tokens\r\n",
    "\r\n",
    "anna_adjective_tokens = []\r\n",
    "for sentence in annaTagged:\r\n",
    "    for word, pos in sentence:\r\n",
    "        if pos in ['JJ', 'JJR', 'JJS']: # adjective, comparative, superlative\r\n",
    "            if len(word)>1:\r\n",
    "                anna_adjective_tokens.append(word)\r\n",
    "anna_freq_adjective = nltk.FreqDist(anna_adjective_tokens)\r\n",
    "\r\n",
    "for word, freq in anna_freq_adjective.most_common(50):\r\n",
    "    print(word,freq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "little 449\n",
      "same 441\n",
      "old 384\n",
      "other 360\n",
      "own 349\n",
      "new 305\n",
      "such 294\n",
      "good 289\n",
      "more 287\n",
      "first 284\n",
      "ll 272\n",
      "young 205\n",
      "great 203\n",
      "long 197\n",
      "much 194\n",
      "whole 189\n",
      "last 186\n",
      "ve 157\n",
      "happy 148\n",
      "better 130\n",
      "white 130\n",
      "glad 124\n",
      "re 123\n",
      "possible 120\n",
      "ready 117\n",
      "many 109\n",
      ".... 108\n",
      "impossible 98\n",
      "full 98\n",
      "best 93\n",
      "right 92\n",
      "high 92\n",
      "true 90\n",
      "certain 85\n",
      "wrong 84\n",
      "next 83\n",
      "short 81\n",
      "nice 79\n",
      "aware 79\n",
      "different 79\n",
      "strange 79\n",
      "Russian 79\n",
      "few 77\n",
      "afraid 74\n",
      "big 73\n",
      "special 71\n",
      "second 70\n",
      "red 70\n",
      "awful 69\n",
      "general 69\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Top 50 adjective tokens\r\n",
    "\r\n",
    "gatsby_adjective_tokens = []\r\n",
    "for sentence in gatsbyTagged:\r\n",
    "    for word, pos in sentence:\r\n",
    "        if pos in ['JJ', 'JJR', 'JJS']: # adjective, comparative, superlative\r\n",
    "            if len(word)>1:\r\n",
    "                gatsby_adjective_tokens.append(word)\r\n",
    "gatsby_freq_adjective = nltk.FreqDist(gatsby_adjective_tokens)\r\n",
    "\r\n",
    "for word, freq in gatsby_freq_adjective.most_common(50):\r\n",
    "    print(word,freq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "little 98\n",
      "old 79\n",
      "other 64\n",
      "ll 46\n",
      "last 44\n",
      "young 43\n",
      "first 41\n",
      "white 39\n",
      "ve 35\n",
      "more 32\n",
      "small 32\n",
      "own 31\n",
      "long 31\n",
      "re 28\n",
      "much 26\n",
      "new 26\n",
      "few 25\n",
      "next 25\n",
      "great 24\n",
      "full 21\n",
      "open 19\n",
      "good 19\n",
      "big 18\n",
      "hot 18\n",
      "whole 17\n",
      "dark 17\n",
      "same 16\n",
      "yellow 16\n",
      "high 15\n",
      "many 15\n",
      "hard 15\n",
      "blue 15\n",
      "green 15\n",
      "such 14\n",
      "several 14\n",
      "right 14\n",
      "least 13\n",
      "certain 13\n",
      "bright 13\n",
      "nice 13\n",
      "deep 13\n",
      "short 13\n",
      "front 13\n",
      "curious 12\n",
      "warm 11\n",
      "enormous 11\n",
      "black 11\n",
      "it. 11\n",
      "cool 11\n",
      "bad 11\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Top 50 adverb tokens\r\n",
    "\r\n",
    "anna_adverb_tokens = []\r\n",
    "for sentence in annaTagged:\r\n",
    "    for word, pos in sentence:\r\n",
    "        if pos in ['RB', 'RBR', 'RBS']: # adverb, comparative, superlative\r\n",
    "            if len(word)>1:\r\n",
    "                anna_adverb_tokens.append(word)\r\n",
    "anna_freq_adverb = nltk.FreqDist(anna_adverb_tokens)\r\n",
    "\r\n",
    "for word, freq in anna_freq_adverb.most_common(50):\r\n",
    "    print(word,freq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "not 3441\n",
      "so 1280\n",
      "now 741\n",
      "very 584\n",
      "only 518\n",
      "too 494\n",
      "more 438\n",
      "just 435\n",
      "still 403\n",
      "again 402\n",
      "then 398\n",
      "never 388\n",
      "up 370\n",
      "away 359\n",
      "always 338\n",
      "once 320\n",
      "even 311\n",
      "there 282\n",
      "here 276\n",
      "back 268\n",
      "well 252\n",
      "down 210\n",
      "as 207\n",
      "quite 203\n",
      "simply 181\n",
      "suddenly 166\n",
      "alone 166\n",
      "long 164\n",
      "most 162\n",
      "Well 158\n",
      "already 149\n",
      "yet 131\n",
      "ever 125\n",
      "together 122\n",
      "soon 119\n",
      "almost 114\n",
      "Now 109\n",
      "especially 109\n",
      "much 108\n",
      "far 108\n",
      "Then 106\n",
      "really 106\n",
      "ve 105\n",
      "often 95\n",
      "immediately 94\n",
      "indeed 92\n",
      "quickly 85\n",
      "else 84\n",
      "Not 79\n",
      "merely 78\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Top 50 adverb tokens\r\n",
    "\r\n",
    "gatsby_adverb_tokens = []\r\n",
    "for sentence in gatsbyTagged:\r\n",
    "    for word, pos in sentence:\r\n",
    "        if pos in ['RB', 'RBR', 'RBS']: # adverb, comparative, superlative\r\n",
    "            if len(word)>1:\r\n",
    "                gatsby_adverb_tokens.append(word)\r\n",
    "gatsby_freq_adverb = nltk.FreqDist(gatsby_adverb_tokens)\r\n",
    "\r\n",
    "for word, freq in gatsby_freq_adverb.most_common(50):\r\n",
    "    print(word,freq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "just 86\n",
      "then 86\n",
      "back 82\n",
      "now 81\n",
      "so 79\n",
      "not 62\n",
      "never 60\n",
      "here 60\n",
      "there 58\n",
      "away 57\n",
      "very 54\n",
      "too 53\n",
      "again 52\n",
      "Then 50\n",
      "down 49\n",
      "only 40\n",
      "more 39\n",
      "even 37\n",
      "up 37\n",
      "always 34\n",
      "suddenly 32\n",
      "still 28\n",
      "ever 27\n",
      "once 27\n",
      "together 25\n",
      "alone 25\n",
      "rather 24\n",
      "ve 23\n",
      "later 22\n",
      "right 21\n",
      "ll 21\n",
      "far 18\n",
      "around 17\n",
      "slowly 17\n",
      "long 17\n",
      "most 16\n",
      "over 16\n",
      "almost 15\n",
      "quickly 15\n",
      "immediately 15\n",
      "as 14\n",
      "already 14\n",
      "So 14\n",
      "forward 13\n",
      "enough 12\n",
      "somewhere 12\n",
      "perhaps 12\n",
      "really 11\n",
      "Now 11\n",
      "about 11\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "## TO DO / YOUR TURN NOW!\r\n",
    "## NOUN EXTRACTION\r\n",
    "## VERB EXTRACTION\r\n",
    "## REMEMBER TO CHECK THE PENN POS TAGS LIST: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\r\n",
    "## TO FIND ALL TAGS"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "anna__noun_tokens = []\r\n",
    "for sentence in annaTagged:\r\n",
    "    for word, pos in sentence:\r\n",
    "        if pos in ['NN', 'NNS', 'NNP', 'NNPS']: # Noun, Plural, Proper, Proper Plural\r\n",
    "            if len(word)>1:\r\n",
    "                anna__noun_tokens.append(word)\r\n",
    "anna__freq_noun = nltk.FreqDist(anna__noun_tokens)\r\n",
    "\r\n",
    "for word, freq in anna__freq_noun.most_common(50):\r\n",
    "    print(word,freq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Levin 1592\n",
      "Vronsky 850\n",
      "Anna 815\n",
      "Kitty 663\n",
      "Alexey 629\n",
      "Alexandrovitch 570\n",
      "time 556\n",
      "man 550\n",
      "Stepan 548\n",
      "Arkadyevitch 547\n",
      "eyes 544\n",
      "face 535\n",
      "nothing 495\n",
      "life 449\n",
      "something 416\n",
      "wife 406\n",
      "hand 379\n",
      "husband 324\n",
      "people 317\n",
      "way 306\n",
      "smile 306\n",
      "everything 306\n",
      "day 301\n",
      "Ivanovitch 301\n",
      "brother 300\n",
      "Sergey 299\n",
      "Yes 292\n",
      "room 291\n",
      "head 288\n",
      ".... 285\n",
      "position 284\n",
      "Dolly 269\n",
      "Oh 262\n",
      "love 259\n",
      "words 258\n",
      "heart 240\n",
      "Chapter 239\n",
      "conversation 236\n",
      "thing 235\n",
      "children 234\n",
      "mother 234\n",
      "feeling 223\n",
      "Alexandrovna 214\n",
      "No 214\n",
      "Darya 209\n",
      "anything 208\n",
      "hands 206\n",
      "Well 206\n",
      "question 205\n",
      "moment 199\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "gatsby_noun_tokens = []\r\n",
    "for sentence in gatsbyTagged:\r\n",
    "    for word, pos in sentence:\r\n",
    "        if pos in ['NN', 'NNS', 'NNP', 'NNPS']: # Noun, Plural, Proper, Proper Plural\r\n",
    "            if len(word)>1:\r\n",
    "                gatsby_noun_tokens.append(word)\r\n",
    "gatsby_freq_noun = nltk.FreqDist(gatsby_noun_tokens)\r\n",
    "\r\n",
    "for word, freq in gatsby_freq_noun.most_common(50):\r\n",
    "    print(word,freq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Gatsby 250\n",
      "Tom 188\n",
      "Daisy 182\n",
      "man 98\n",
      "house 90\n",
      "eyes 85\n",
      "Mr. 78\n",
      "Wilson 77\n",
      "time 75\n",
      "way 72\n",
      "moment 70\n",
      "Jordan 70\n",
      "door 65\n",
      "night 65\n",
      "hand 63\n",
      "car 61\n",
      "something 60\n",
      "voice 58\n",
      "people 57\n",
      "room 53\n",
      "face 50\n",
      "girl 44\n",
      "New 43\n",
      "men 42\n",
      "day 41\n",
      "head 40\n",
      "Baker 39\n",
      "name 38\n",
      "hands 36\n",
      "years 35\n",
      "thing 34\n",
      "afternoon 34\n",
      "Miss 34\n",
      "sport 34\n",
      "West 33\n",
      "hour 33\n",
      "minute 32\n",
      "nothing 31\n",
      "Egg 30\n",
      "Well 30\n",
      "table 30\n",
      "Wolfshiem 29\n",
      "York 28\n",
      "Mrs. 28\n",
      "life 27\n",
      "light 27\n",
      "morning 26\n",
      "things 26\n",
      "air 25\n",
      "Oh 25\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "anna_verb_tokens = []\r\n",
    "for sentence in annaTagged:\r\n",
    "    for word, pos in sentence:\r\n",
    "        if pos in ['VB','VBD','VBG', 'VBP','VBZ','VBN']: # Noun, Plural, Proper, Proper Plural\r\n",
    "            if len(word)>1:\r\n",
    "                anna_verb_tokens.append(word)\r\n",
    "anna_freq_verb = nltk.FreqDist(anna_verb_tokens)\r\n",
    "\r\n",
    "for word, freq in anna_freq_verb.most_common(50):\r\n",
    "    print(word,freq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "was 5284\n",
      "had 3846\n",
      "said 2721\n",
      "be 1766\n",
      "is 1357\n",
      "have 1231\n",
      "were 1227\n",
      "been 1057\n",
      "did 923\n",
      "do 704\n",
      "went 660\n",
      "know 655\n",
      "go 641\n",
      "are 595\n",
      "see 584\n",
      "felt 549\n",
      "come 512\n",
      "say 499\n",
      "don 438\n",
      "thought 434\n",
      "came 420\n",
      "saw 416\n",
      "made 402\n",
      "has 399\n",
      "going 393\n",
      "knew 384\n",
      "began 365\n",
      "looking 342\n",
      "looked 333\n",
      "am 330\n",
      "asked 320\n",
      "think 290\n",
      "seemed 289\n",
      "put 287\n",
      "get 280\n",
      "got 277\n",
      "make 259\n",
      "told 257\n",
      "being 254\n",
      "tell 250\n",
      "answered 249\n",
      "took 240\n",
      "heard 230\n",
      "let 226\n",
      "want 222\n",
      "take 217\n",
      "understand 211\n",
      "done 207\n",
      "turned 205\n",
      "left 183\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "gatsby_verb_tokens = []\r\n",
    "for sentence in gatsbyTagged:\r\n",
    "    for word, pos in sentence:\r\n",
    "        if pos in ['VB','VBD','VBG', 'VBP','VBZ','VBN']: # Noun, Plural, Proper, Proper Plural\r\n",
    "            if len(word)>1:\r\n",
    "                gatsby_verb_tokens.append(word)\r\n",
    "gatsby_freq_verb = nltk.FreqDist(gatsby_verb_tokens)\r\n",
    "\r\n",
    "for word, freq in gatsby_freq_verb.most_common(50):\r\n",
    "    print(word,freq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "was 761\n",
      "had 378\n",
      "said 233\n",
      "were 170\n",
      "have 129\n",
      "be 121\n",
      "came 108\n",
      "been 106\n",
      "is 92\n",
      "went 90\n",
      "know 88\n",
      "got 84\n",
      "looked 81\n",
      "didn 70\n",
      "see 68\n",
      "don 66\n",
      "going 66\n",
      "turned 64\n",
      "get 64\n",
      "made 63\n",
      "do 60\n",
      "go 60\n",
      "think 59\n",
      "come 57\n",
      "want 55\n",
      "knew 52\n",
      "saw 51\n",
      "began 50\n",
      "took 48\n",
      "told 44\n",
      "thought 43\n",
      "asked 43\n",
      "are 39\n",
      "seemed 39\n",
      "heard 39\n",
      "left 37\n",
      "did 35\n",
      "say 34\n",
      "found 34\n",
      "looking 34\n",
      "seen 31\n",
      "wasn 31\n",
      "sat 31\n",
      "cried 29\n",
      "tell 28\n",
      "wanted 27\n",
      "take 27\n",
      "called 27\n",
      "gave 26\n",
      "moved 26\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Now we have two lists of POS tags combinations we can compare\r\n",
    "# We need to get the sentences back from the tagging exercise and run some stats\r\n",
    "\r\n",
    "# Create a list of original sentences from the ADJECTIVE phrase subset:\r\n",
    "anna_adjph_whole_sentences = []\r\n",
    "\r\n",
    "# loop over the sentences in the adjective phrase sentences we created:\r\n",
    "for sents in anna_adjph_tags:\r\n",
    "    temp=''\r\n",
    "    for (word,tag) in sents:\r\n",
    "        temp += word+' '\r\n",
    "        anna_adjph_whole_sentences.append(temp)\r\n",
    "        \r\n",
    "print(len(anna_adjph_whole_sentences))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5681\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Now we have two lists of POS tags combinations we can compare\r\n",
    "# We need to get the sentences back from the tagging exercise and run some stats\r\n",
    "\r\n",
    "# Create a list of original sentences from the ADJECTIVE phrase subset:\r\n",
    "gatsby_adjph_whole_sentences = []\r\n",
    "\r\n",
    "# loop over the sentences in the adjective phrase sentences we created:\r\n",
    "for sents in gatsby_adjph_tags:\r\n",
    "    temp=''\r\n",
    "    for (word,tag) in sents:\r\n",
    "        temp += word+' '\r\n",
    "        gatsby_adjph_whole_sentences.append(temp)\r\n",
    "        \r\n",
    "print(len(gatsby_adjph_whole_sentences))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "617\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Create a list of original sentences from the ADVERB phrase subset:\r\n",
    "anna_advph_whole_sentences = []\r\n",
    "\r\n",
    "# loop over the sentences in the adjective phrase sentences we created:\r\n",
    "for sents in anna_advph_tags:\r\n",
    "    temp=''\r\n",
    "    for (word,tag) in sents:\r\n",
    "        temp += word+' '\r\n",
    "        anna_advph_whole_sentences.append(temp)\r\n",
    "        \r\n",
    "print(len(anna_advph_whole_sentences))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4226\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Create a list of original sentences from the ADVERB phrase subset:\r\n",
    "gatsby_advph_whole_sentences = []\r\n",
    "\r\n",
    "# loop over the sentences in the adjective phrase sentences we created:\r\n",
    "for sents in gatsby_advph_tags:\r\n",
    "    temp=''\r\n",
    "    for (word,tag) in sents:\r\n",
    "        temp += word+' '\r\n",
    "        gatsby_advph_whole_sentences.append(temp)\r\n",
    "        \r\n",
    "print(len(gatsby_advph_whole_sentences))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "459\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# OPTIONAL STEP: Combine lists together to have a single list of adjective/adverb phrases:\r\n",
    "# Useful to know which sentences are heavy in qualifiers\r\n",
    "\r\n",
    "# create a new variable to store all adjective phrase sentences\r\n",
    "anna_adv_adj_phrase_sentences = anna_adjph_whole_sentences\r\n",
    "\r\n",
    "# iterate over adverb phrase sentences\r\n",
    "for sent in anna_advph_whole_sentences:\r\n",
    "    # if a sentence is not in the adjective phrases list imported\r\n",
    "    if sent not in anna_adv_adj_phrase_sentences:\r\n",
    "        # attach that sentence\r\n",
    "        anna_adv_adj_phrase_sentences.append(sent)\r\n",
    "\r\n",
    "# print the lenght of the list (i.e. number of sentences with both adjective and adverb phrases)\r\n",
    "print(len(anna_adv_adj_phrase_sentences))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6524\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# OPTIONAL STEP: Combine lists together to have a single list of adjective/adverb phrases:\r\n",
    "# Useful to know which sentences are heavy in qualifiers\r\n",
    "\r\n",
    "# create a new variable to store all adjective phrase sentences\r\n",
    "gatsby_adv_adj_phrase_sentences = gatsby_adjph_whole_sentences\r\n",
    "\r\n",
    "# iterate over adverb phrase sentences\r\n",
    "for sent in gatsby_advph_whole_sentences:\r\n",
    "    # if a sentence is not in the adjective phrases list imported\r\n",
    "    if sent not in gatsby_adv_adj_phrase_sentences:\r\n",
    "        # attach that sentence\r\n",
    "        gatsby_adv_adj_phrase_sentences.append(sent)\r\n",
    "\r\n",
    "# print the lenght of the list (i.e. number of sentences with both adjective and adverb phrases)\r\n",
    "print(len(gatsby_adv_adj_phrase_sentences))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "815\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Following our NLTK textbook, Writing Structural Programs chapter\r\n",
    "# section on Procedural vs Declarative style (http://www.nltk.org/book_1ed/ch04.html) \r\n",
    "\r\n",
    "## CORPUS STATISTICS--SENTENCES LENGTH\r\n",
    "\r\n",
    "# Calculating the average length of sentences in the entire corpus\r\n",
    "# from http://www.nltk.org/book_1ed/ch04.html\r\n",
    "anna_total_corpus = sum(len(sent) for sent in annaKSplit) # remember: 'textsplit' is our text split into sentences\r\n",
    "print(anna_total_corpus / len(annaKSplit))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "117.5211771013284\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Following our NLTK textbook, Writing Structural Programs chapter\r\n",
    "# section on Procedural vs Declarative style (http://www.nltk.org/book_1ed/ch04.html) \r\n",
    "\r\n",
    "## CORPUS STATISTICS--SENTENCES LENGTH\r\n",
    "\r\n",
    "# Calculating the average length of sentences in the entire corpus\r\n",
    "# from http://www.nltk.org/book_1ed/ch04.html\r\n",
    "gatsby_total_corpus = sum(len(sent) for sent in gatsbySplit) # remember: 'textsplit' is our text split into sentences\r\n",
    "print(gatsby_total_corpus / len(gatsbySplit))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "111.43173431734317\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Calculate the average length of an adjective phrase sentence\r\n",
    "# We can then compare the average length of the adjective phrases to \r\n",
    "# the average sentences we calculated for all sentences in the corpus\r\n",
    "anna_total_adjph_sentences = sum(len(sent) for sent in anna_adjph_whole_sentences) # adjph_whole_sentences stores our adjective phrases\r\n",
    "print(anna_total_adjph_sentences / len(anna_adjph_whole_sentences))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.89653586756591\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Calculate the average length of an adjective phrase sentence\r\n",
    "# We can then compare the average length of the adjective phrases to \r\n",
    "# the average sentences we calculated for all sentences in the corpus\r\n",
    "gatsby_total_adjph_sentences = sum(len(sent) for sent in gatsby_adjph_whole_sentences) # adjph_whole_sentences stores our adjective phrases\r\n",
    "print(gatsby_total_adjph_sentences / len(gatsby_adjph_whole_sentences))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10.067484662576687\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "f15837fdae91b30dab61da71d8b87089474f4d12bf60a1f1e36f7e67523581b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}