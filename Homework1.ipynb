{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "source": [
    "from gutenberg.acquire import load_etext\r\n",
    "from gutenberg.cleanup import strip_headers\r\n",
    "import nltk"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "source": [
    "text1 = strip_headers(load_etext(1399)).strip()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "print(text1[:50])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Illustration]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ANNA KARENINA \n",
      "\n",
      " by Leo\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "type(text1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "len(text1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2004610"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "text1Tokens = nltk.word_tokenize(text1)\r\n",
    "Pstem = nltk.PorterStemmer()\r\n",
    "Lstem = nltk.LancasterStemmer()\r\n",
    "text1Tokens = [Pstem.stem(t) for t in text1Tokens]\r\n",
    "len(text1Tokens)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "430347"
      ]
     },
     "metadata": {},
     "execution_count": 202
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "source": [
    "text1Tokens = [w.lower() for w in text1Tokens]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "source": [
    "text1vocab = sorted(set(text1Tokens))\r\n",
    "text1vocab[:50]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['!',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '.',\n",
       " '...',\n",
       " '....',\n",
       " '1',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '17,015',\n",
       " '17th',\n",
       " '18',\n",
       " '18,038',\n",
       " '1863',\n",
       " '1864',\n",
       " '19',\n",
       " '2',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2nd',\n",
       " '3',\n",
       " '30',\n",
       " '30th',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9']"
      ]
     },
     "metadata": {},
     "execution_count": 204
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "from nltk import FreqDist"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "text1Dist= FreqDist(text1Tokens)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "source": [
    "text1TopToken = text1Dist.most_common(50)\r\n",
    "for pair in text1TopToken:\r\n",
    "    print(pair)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(',', 30995)\n",
      "('the', 17506)\n",
      "('.', 14986)\n",
      "('and', 12845)\n",
      "('to', 10117)\n",
      "('of', 8603)\n",
      "('he', 7780)\n",
      "('“', 7013)\n",
      "('”', 6982)\n",
      "('’', 6631)\n",
      "('a', 6116)\n",
      "('in', 5928)\n",
      "('that', 5446)\n",
      "('wa', 5296)\n",
      "('hi', 5230)\n",
      "('her', 5064)\n",
      "('it', 4634)\n",
      "('i', 4441)\n",
      "('she', 4375)\n",
      "('had', 3850)\n",
      "('with', 3744)\n",
      "('not', 3520)\n",
      "('s', 3390)\n",
      "('you', 3265)\n",
      "('but', 3148)\n",
      "('him', 3103)\n",
      "('at', 2913)\n",
      "('said', 2721)\n",
      "('for', 2698)\n",
      "('as', 2430)\n",
      "('?', 2362)\n",
      "('on', 2193)\n",
      "('be', 2031)\n",
      "('all', 1899)\n",
      "('what', 1779)\n",
      "('!', 1716)\n",
      "(';', 1683)\n",
      "('levin', 1621)\n",
      "('so', 1517)\n",
      "('have', 1421)\n",
      "('t', 1410)\n",
      "('is', 1406)\n",
      "('thi', 1360)\n",
      "('from', 1304)\n",
      "('up', 1301)\n",
      "('were', 1233)\n",
      "('one', 1230)\n",
      "('they', 1224)\n",
      "('there', 1188)\n",
      "('no', 1135)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "source": [
    "import re\r\n",
    "nltkstopwords=nltk.corpus.stopwords.words('english')\r\n",
    "print(type(nltkstopwords))\r\n",
    "additionalstopwords = ['said']\r\n",
    "nltkstopwords = nltkstopwords + additionalstopwords\r\n",
    "print(type(nltkstopwords))\r\n",
    "nltkstopwords = [Pstem.stem(t) for t in nltkstopwords]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "source": [
    "\r\n",
    "def alpha_filter(w):\r\n",
    "    pattern = re.compile('^[^a-z]+$')\r\n",
    "    pattern2 = re.compile('_[a-z]+_?')\r\n",
    "    if (pattern.match(w)):\r\n",
    "        return True\r\n",
    "    elif (pattern2.match(w)):\r\n",
    "        return True\r\n",
    "    else:\r\n",
    "        return False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "source": [
    "alphatext1 = [w for w in text1Tokens if not alpha_filter(w)]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "source": [
    "print(alphatext1[:100])\r\n",
    "len(alphatext1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['illustr', 'anna', 'karenina', 'by', 'leo', 'tolstoy', 'translat', 'by', 'constanc', 'garnett', 'content', 'part', 'one', 'part', 'two', 'part', 'three', 'part', 'four', 'part', 'five', 'part', 'six', 'part', 'seven', 'part', 'eight', 'part', 'one', 'chapter', 'happi', 'famili', 'are', 'all', 'alik', 'everi', 'unhappi', 'famili', 'is', 'unhappi', 'in', 'it', 'own', 'way', 'everyth', 'wa', 'in', 'confus', 'in', 'the', 'oblonski', 'hous', 'the', 'wife', 'had', 'discov', 'that', 'the', 'husband', 'wa', 'carri', 'on', 'an', 'intrigu', 'with', 'a', 'french', 'girl', 'who', 'had', 'been', 'a', 'gover', 'in', 'their', 'famili', 'and', 'she', 'had', 'announc', 'to', 'her', 'husband', 'that', 'she', 'could', 'not', 'go', 'on', 'live', 'in', 'the', 'same', 'hous', 'with', 'him', 'thi', 'posit', 'of', 'affair']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "355630"
      ]
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "source": [
    "alphatext1 = [w for w in alphatext1 if not w in nltkstopwords]\r\n",
    "print(alphatext1[:100])\r\n",
    "print(len(alphatext1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['illustr', 'anna', 'karenina', 'leo', 'tolstoy', 'translat', 'constanc', 'garnett', 'content', 'part', 'one', 'part', 'two', 'part', 'three', 'part', 'four', 'part', 'five', 'part', 'six', 'part', 'seven', 'part', 'eight', 'part', 'one', 'chapter', 'happi', 'famili', 'alik', 'everi', 'unhappi', 'famili', 'unhappi', 'way', 'everyth', 'confus', 'oblonski', 'hous', 'wife', 'discov', 'husband', 'carri', 'intrigu', 'french', 'girl', 'gover', 'famili', 'announc', 'husband', 'could', 'go', 'live', 'hous', 'posit', 'affair', 'last', 'three', 'day', 'husband', 'wife', 'member', 'famili', 'household', 'pain', 'consciou', 'everi', 'person', 'hous', 'felt', 'sens', 'live', 'togeth', 'stray', 'peopl', 'brought', 'togeth', 'chanc', 'inn', 'common', 'one', 'anoth', 'member', 'famili', 'household', 'oblonski', 'wife', 'leav', 'room', 'husband', 'home', 'three', 'day', 'children', 'ran', 'wild', 'hous', 'english', 'gover']\n",
      "157064\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "source": [
    "KareniaDist = FreqDist(alphatext1)\r\n",
    "KareniaItems = KareniaDist.most_common(50)\r\n",
    "for item in KareniaItems:\r\n",
    "    print(item)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('levin', 1621)\n",
      "('one', 1230)\n",
      "('go', 1081)\n",
      "('would', 1044)\n",
      "('look', 1001)\n",
      "('could', 970)\n",
      "('come', 882)\n",
      "('vronski', 855)\n",
      "('anna', 818)\n",
      "('know', 796)\n",
      "('see', 775)\n",
      "('say', 702)\n",
      "('like', 689)\n",
      "('kitti', 668)\n",
      "('went', 660)\n",
      "('thought', 658)\n",
      "('time', 642)\n",
      "('hand', 637)\n",
      "('smile', 631)\n",
      "('alexey', 629)\n",
      "('well', 624)\n",
      "('face', 588)\n",
      "('love', 584)\n",
      "('alexandrovitch', 570)\n",
      "('eye', 567)\n",
      "('feel', 556)\n",
      "('felt', 553)\n",
      "('man', 550)\n",
      "('stepan', 548)\n",
      "('arkadyevitch', 547)\n",
      "('ye', 531)\n",
      "('noth', 523)\n",
      "('though', 518)\n",
      "('ask', 488)\n",
      "('think', 488)\n",
      "('get', 485)\n",
      "('talk', 481)\n",
      "('even', 474)\n",
      "('littl', 456)\n",
      "('want', 451)\n",
      "('life', 450)\n",
      "('answer', 431)\n",
      "('still', 430)\n",
      "('long', 426)\n",
      "('someth', 424)\n",
      "('saw', 422)\n",
      "('without', 420)\n",
      "('came', 420)\n",
      "('take', 417)\n",
      "('day', 416)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "source": [
    "from nltk.collocations import *\r\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\r\n",
    "trigrams = nltk.collocations.TrigramAssocMeasures()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "source": [
    "finder = BigramCollocationFinder.from_words(text1Tokens)\r\n",
    "finder.apply_word_filter(alpha_filter)\r\n",
    "finder.apply_word_filter(lambda w: w in nltkstopwords)\r\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "source": [
    "for bi in scored[:50]:\r\n",
    "    print(bi)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(('alexey', 'alexandrovitch'), 0.0013245125445280205)\n",
      "(('stepan', 'arkadyevitch'), 0.0012687435952847353)\n",
      "(('sergey', 'ivanovitch'), 0.0006738748033563612)\n",
      "(('darya', 'alexandrovna'), 0.0004740360685679231)\n",
      "(('lidia', 'ivanovna'), 0.0002463128591578424)\n",
      "(('old', 'man'), 0.00019751502856996795)\n",
      "(('look', 'round'), 0.00019286761613302754)\n",
      "(('go', 'away'), 0.0001858964974776169)\n",
      "(('countess', 'lidia'), 0.00017892537882220627)\n",
      "(('agafea', 'mihalovna'), 0.0001673068477298552)\n",
      "(('one', 'thing'), 0.00013709866688974245)\n",
      "(('anna', 'arkadyevna'), 0.0001254801357973914)\n",
      "(('great', 'deal'), 0.00011618531092351056)\n",
      "(('come', 'back'), 0.00011386160470504035)\n",
      "(('let', 'us'), 0.00010921419226809993)\n",
      "(('konstantin', 'levin'), 0.00010689048604962972)\n",
      "(('madam', 'stahl'), 0.00010689048604962972)\n",
      "(('first', 'time'), 0.0001022430736126893)\n",
      "(('levin', 'went'), 9.991936739421908e-05)\n",
      "(('sick', 'man'), 9.527195495727866e-05)\n",
      "(('one', 'must'), 8.830083630186803e-05)\n",
      "(('old', 'princ'), 8.36534238649276e-05)\n",
      "(('one', 'anoth'), 8.36534238649276e-05)\n",
      "(('young', 'man'), 8.132971764645739e-05)\n",
      "(('levin', 'could'), 7.900601142798719e-05)\n",
      "(('levin', 'felt'), 7.668230520951697e-05)\n",
      "(('madam', 'karenina'), 7.668230520951697e-05)\n",
      "(('marya', 'nikolaevna'), 7.668230520951697e-05)\n",
      "(('next', 'day'), 7.668230520951697e-05)\n",
      "(('went', 'back'), 7.435859899104675e-05)\n",
      "(('long', 'ago'), 7.203489277257655e-05)\n",
      "(('sever', 'time'), 7.203489277257655e-05)\n",
      "(('come', 'along'), 6.971118655410633e-05)\n",
      "(('konstantin', 'dmitrievitch'), 6.971118655410633e-05)\n",
      "(('say', 'someth'), 6.971118655410633e-05)\n",
      "(('answer', 'levin'), 6.738748033563613e-05)\n",
      "(('could', 'never'), 6.738748033563613e-05)\n",
      "(('left', 'alon'), 6.738748033563613e-05)\n",
      "(('go', 'back'), 6.506377411716591e-05)\n",
      "(('levin', 'saw'), 6.506377411716591e-05)\n",
      "(('thought', 'levin'), 6.506377411716591e-05)\n",
      "(('littl', 'girl'), 6.27400678986957e-05)\n",
      "(('one', 'side'), 6.27400678986957e-05)\n",
      "(('thank', 'god'), 6.27400678986957e-05)\n",
      "(('turn', 'away'), 6.27400678986957e-05)\n",
      "(('vassenka', 'veslovski'), 6.0416361680225495e-05)\n",
      "(('everi', 'time'), 5.809265546175528e-05)\n",
      "(('one', 'would'), 5.809265546175528e-05)\n",
      "(('princess', 'varvara'), 5.809265546175528e-05)\n",
      "(('came', 'back'), 5.576894924328507e-05)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "source": [
    "finder.apply_freq_filter(5)\r\n",
    "Score2 = finder.score_ngrams(bigram_measures.pmi)\r\n",
    "for i in Score2[:50]:\r\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(('mashkin', 'upland'), 15.907785964043683)\n",
      "(('grand', 'duchess'), 15.545215884658976)\n",
      "(('bridal', 'pair'), 14.867143979546338)\n",
      "(('swollen', 'vein'), 14.867143979546338)\n",
      "(('nativ', 'tribe'), 14.808250290492769)\n",
      "(('liza', 'merkalova'), 14.255709267463988)\n",
      "(('alexand', 'nevski'), 14.13017838538013)\n",
      "(('lizaveta', 'petrovna'), 14.068777840715986)\n",
      "(('mademoisel', 'linon'), 13.878639618384167)\n",
      "(('mihail', 'vassilievitch'), 13.73786096260137)\n",
      "(('vassili', 'lukitch'), 13.585857869156323)\n",
      "(('miss', 'hool'), 13.42973866723904)\n",
      "(('scotch', 'cap'), 13.42973866723904)\n",
      "(('fur', 'cloak'), 13.168246426213651)\n",
      "(('happiest', 'frame'), 13.009162984418765)\n",
      "(('polit', 'economi'), 12.97817529193508)\n",
      "(('counting-hous', 'clerk'), 12.889170285876336)\n",
      "(('storm', 'cloud'), 12.730247778491494)\n",
      "(('marya', 'borissovna'), 12.692773073072832)\n",
      "(('marya', 'yevgenyevna'), 12.692773073072832)\n",
      "(('marya', 'nikolaevna'), 12.69277307307283)\n",
      "(('lime', 'tree'), 12.575589533702493)\n",
      "(('agafea', 'mihalovna'), 12.505687520472337)\n",
      "(('seltzer', 'water'), 12.4672133726577)\n",
      "(('summer', 'villa'), 12.457753043408637)\n",
      "(('thrash', 'machin'), 12.313042442529941)\n",
      "(('marya', 'philimonovna'), 12.207346245902592)\n",
      "(('highest', 'degre'), 12.175982074993255)\n",
      "(('sleepless', 'night'), 12.009162984418765)\n",
      "(('game', 'bag'), 11.971749022775647)\n",
      "(('flush', 'hotli'), 11.936406641983451)\n",
      "(('gray', 'whisker'), 11.933781172576628)\n",
      "(('lidia', 'ivanovna'), 11.920234640738682)\n",
      "(('district', 'council'), 11.813067306790545)\n",
      "(('madam', 'lvova'), 11.796277648826694)\n",
      "(('madam', 'stahl'), 11.765250753206066)\n",
      "(('scarc', 'percept'), 11.760944575714412)\n",
      "(('birch', 'tree'), 11.686620846091238)\n",
      "(('madam', 'karenina'), 11.555269549322897)\n",
      "(('utterli', 'unlik'), 11.551605559948074)\n",
      "(('railway', 'station'), 11.461293401113885)\n",
      "(('malign', 'gentleman'), 11.449916549176669)\n",
      "(('countess', 'nordston'), 11.357588881483204)\n",
      "(('countess', 'vronskaya'), 11.357588881483203)\n",
      "(('fifti', 'roubl'), 11.343582023489324)\n",
      "(('pyotr', 'dmitrievitch'), 11.324050766706527)\n",
      "(('villag', 'elder'), 11.308176687358124)\n",
      "(('fine', 'weather'), 11.305749949963586)\n",
      "(('hardli', 'percept'), 11.305749949963584)\n",
      "(('deep', 'breath'), 11.26392977426896)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "source": [
    "triFinder = TrigramCollocationFinder.from_words(text1Tokens)\r\n",
    "triFinder.apply_word_filter(alpha_filter)\r\n",
    "triFinder.apply_word_filter(lambda w: w in nltkstopwords)\r\n",
    "triFinder.apply_freq_filter(5)\r\n",
    "Triscored2 = triFinder.score_ngrams(trigrams.pmi)\r\n",
    "for w in Triscored2:\r\n",
    "    print(w[:50])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(('strain', 'everi', 'nerv'), 23.309266371241208)\n",
      "(('princess', 'marya', 'borissovna'), 22.841225629921855)\n",
      "(('countess', 'lidia', 'ivanovna'), 22.759356433287632)\n",
      "(('answer', 'darya', 'alexandrovna'), 15.551839689518808)\n",
      "(('let', 'us', 'talk'), 15.258293843062347)\n",
      "(('address', 'alexey', 'alexandrovitch'), 14.94292354654046)\n",
      "(('let', 'us', 'go'), 14.742112815677437)\n",
      "(('littl', 'old', 'man'), 14.05300415376077)\n",
      "(('sergey', 'ivanovitch', 'smile'), 13.993092321149579)\n",
      "(('stepan', 'arkadyevitch', 'took'), 13.908925830940685)\n",
      "(('alexey', 'alexandrovitch', 'took'), 13.873013042098822)\n",
      "(('stepan', 'arkadyevitch', 'saw'), 13.515753477742297)\n",
      "(('alexey', 'alexandrovitch', 'got'), 13.449767790943145)\n",
      "(('alexey', 'alexandrovitch', 'saw'), 13.427373269006306)\n",
      "(('ask', 'stepan', 'arkadyevitch'), 13.306115328886598)\n",
      "(('alexey', 'alexandrovitch', 'went'), 13.071656860662664)\n",
      "(('stepan', 'arkadyevitch', 'went'), 12.870530452203667)\n",
      "(('answer', 'stepan', 'arkadyevitch'), 12.807236702247756)\n",
      "(('stepan', 'arkadyevitch', 'smile'), 12.742711393524544)\n",
      "(('stepan', 'arkadyevitch', 'ask'), 12.628043423773967)\n",
      "(('stepan', 'arkadyevitch', 'felt'), 12.447645091102146)\n",
      "(('alexey', 'alexandrovitch', 'smile'), 12.262013762009786)\n",
      "(('thought', 'alexey', 'alexandrovitch'), 12.201566183257093)\n",
      "(('could', 'say', 'noth'), 12.02244647857658)\n",
      "(('stepan', 'arkadyevitch', 'could'), 11.636939824262363)\n",
      "(('alexey', 'alexandrovitch', 'would'), 11.535603960422453)\n",
      "(('levin', 'went', 'back'), 11.239403500062323)\n",
      "(('levin', 'look', 'round'), 11.133630545964238)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f15837fdae91b30dab61da71d8b87089474f4d12bf60a1f1e36f7e67523581b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}